{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "990ec368-11d9-49cc-8ea6-65a1499fa5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d4ac5ff-0883-4dbd-a84e-a1995819f869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        qid            qname  \\\n",
      "0     QID18    TechEndorse_1   \n",
      "1     QID18    TechEndorse_2   \n",
      "2     QID18    TechEndorse_3   \n",
      "3     QID18    TechEndorse_4   \n",
      "4     QID18    TechEndorse_5   \n",
      "..      ...              ...   \n",
      "134  QID103  AIAgentObsWrite   \n",
      "135   QID92  AIAgentExternal   \n",
      "136  QID104  AIAgentExtWrite   \n",
      "137  QID100          AIHuman   \n",
      "138   QID93           AIOpen   \n",
      "\n",
      "                                              question type  \\\n",
      "0    What attracts you to a technology or causes yo...   RO   \n",
      "1    What attracts you to a technology or causes yo...   RO   \n",
      "2    What attracts you to a technology or causes yo...   RO   \n",
      "3    What attracts you to a technology or causes yo...   RO   \n",
      "4    What attracts you to a technology or causes yo...   RO   \n",
      "..                                                 ...  ...   \n",
      "134  Was the tool or tools for AI agent observabili...   TE   \n",
      "135  You indicated you use or develop AI agents as ...   MC   \n",
      "136  Was the out-of-the-box agents, copilots or ass...   TE   \n",
      "137  In the future, if AI can do most coding tasks,...   MC   \n",
      "138  Looking ahead 3–5 years, what skills do you be...   TE   \n",
      "\n",
      "                                         sub  sq_id  \n",
      "0    AI integration or AI Agent capabilities    1.0  \n",
      "1                            Easy-to-use API    2.0  \n",
      "2                    Robust and complete API    3.0  \n",
      "3       Customizable and manageable codebase    4.0  \n",
      "4                     Reputation for quality    5.0  \n",
      "..                                       ...    ...  \n",
      "134                                      NaN    NaN  \n",
      "135                                      NaN    NaN  \n",
      "136                                      NaN    NaN  \n",
      "137                                      NaN    NaN  \n",
      "138                                      NaN    NaN  \n",
      "\n",
      "[139 rows x 6 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49191 entries, 0 to 49190\n",
      "Columns: 172 entries, ResponseId to JobSat\n",
      "dtypes: float64(52), int64(1), object(119)\n",
      "memory usage: 64.6+ MB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_9096\\1348559211.py:2: DtypeWarning: Columns (56,74,92,97,98,105,109,110,132,162,165) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  survey_results_public=sp_res=pd.read_csv(r'C:\\Users\\User\\Desktop\\GoIT cours Data Analytic\\Python_project\\stack-overflow-developer-survey-2025\\survey_results_public.csv')\n"
     ]
    }
   ],
   "source": [
    "#Data loading & inspection\n",
    "survey_results_public=sp_res=pd.read_csv(r'C:\\Users\\User\\Desktop\\GoIT cours Data Analytic\\Python_project\\stack-overflow-developer-survey-2025\\survey_results_public.csv')\n",
    "survey_results_schema=sch_res=pd.read_csv(r'C:\\Users\\User\\Desktop\\GoIT cours Data Analytic\\Python_project\\stack-overflow-developer-survey-2025\\survey_results_schema.csv')\n",
    "print(sch_res)\n",
    "\n",
    "print(sp_res.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4079fa71-c0bc-4edf-8c7d-e4f0b4f43e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total respondents amount: 49191\n",
      "Unique respondents amount: 49191\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with fewer than 1000 non-null values to ensure data quality\n",
    "sp_res = sp_res.dropna(axis=1, thresh=1000)\n",
    "# Count the number of unique Respondent IDs to determine the sample size\n",
    "respondents_count = sp_res['ResponseId'].count()\n",
    "# Verify that there are no duplicate entries in the ID column\n",
    "unique_respondents = sp_res['ResponseId'].nunique()\n",
    "\n",
    "print(f\"Total respondents amount: {respondents_count}\")\n",
    "print(f\"Unique respondents amount: {unique_respondents}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7befb4f4-c5f6-490c-9c2d-7fccd92562dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions amount to check : 116\n"
     ]
    }
   ],
   "source": [
    "### Analysis of Respondent Completion Rates\n",
    "# 1. Extract the list of question names from the schema file (using the 'qname' field)\n",
    "# Create a set for efficient intersection later\n",
    "sch_res_questions = set(sch_res['qname'])\n",
    "\n",
    "# 2. Get the set of columns present in the main dataset\n",
    "survey_columns = set(sp_res.columns)\n",
    "\n",
    "# 3. Perform set intersection to find overlapping columns\n",
    "# This identifies columns that exist in both the schema and the survey data\n",
    "questions_to_check = list(sch_res_questions.intersection(survey_columns))\n",
    "\n",
    "print(f\"Questions amount to check : {len(questions_to_check)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa6efb48-ef0a-4a7c-8fd8-58bd9544473d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete responses amount: 0\n",
      "Top15 of the most filed columns:\n",
      "ResponseId           49191\n",
      "MainBranch           49191\n",
      "Age                  49191\n",
      "Employment           48339\n",
      "EdLevel              48149\n",
      "LearnCodeChoose      46858\n",
      "LearnCodeAI          45201\n",
      "EmploymentAddl       44875\n",
      "DevType              43680\n",
      "YearsCode            43042\n",
      "WorkExp              42893\n",
      "TechEndorseIntro     37556\n",
      "PurchaseInfluence    37437\n",
      "AIThreat             36078\n",
      "TechEndorse_4        35975\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filter the main dataset to keep only the overlapping columns\n",
    "# Remove rows that contain AT LEAST ONE missing value (NaN)\n",
    "respondents_without_nans = sp_res[questions_to_check].dropna(how='any')\n",
    "\n",
    "#Final count of complete responses\n",
    "final_count = len(respondents_without_nans)\n",
    "\n",
    "# Count non-null values for each feature and sort them in descending order\n",
    "# This helps identify which questions were answered most frequently\n",
    "top_filled = sp_res.count().sort_values(ascending=False).head(15)\n",
    "\n",
    "print(f\"Complete responses amount: {final_count}\")\n",
    "print(\"Top15 of the most filed columns:\")\n",
    "print(top_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c00f6798-1043-4c04-96d5-296ebaca29b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero reply columns: 0\n",
      "Maximum number of answers is 114 of 116 questions.\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any columns in the list where 100% of the values are NaN\n",
    "# (Ensuring no columns are completely empty)\n",
    "completeness = sp_res[questions_to_check].notna().sum()\n",
    "zero_reply_cols = completeness[completeness == 0]\n",
    "\n",
    "# Calculate the total number of responses provided by each individual respondent\n",
    "# (Creating a response count per row)\n",
    "responses_count = sp_res[questions_to_check].count(axis=1)\n",
    "\n",
    "# Find the maximum number of answers provided by a single respondent\n",
    "# (Identifying the highest completion level in the dataset)\n",
    "max_answers = responses_count.max()\n",
    "total_questions = len(questions_to_check)\n",
    "\n",
    "print(f\"Zero reply columns: {len(zero_reply_cols)}\")\n",
    "print(f\"Maximum number of answers is {max_answers} of {total_questions} questions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16c301ea-600f-40a5-a256-185cb99ab6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. ResponseId\n",
      "1. MainBranch\n",
      "2. Age\n",
      "3. EdLevel\n",
      "4. Employment\n",
      "5. EmploymentAddl\n",
      "6. WorkExp\n",
      "7. LearnCodeChoose\n",
      "8. LearnCode\n",
      "9. LearnCodeAI\n",
      "10. AILearnHow\n",
      "11. YearsCode\n",
      "12. DevType\n",
      "13. OrgSize\n",
      "14. ICorPM\n",
      "15. RemoteWork\n",
      "16. PurchaseInfluence\n",
      "17. TechEndorseIntro\n",
      "18. TechEndorse_1\n",
      "19. TechEndorse_2\n",
      "20. TechEndorse_3\n",
      "21. TechEndorse_4\n",
      "22. TechEndorse_5\n",
      "23. TechEndorse_6\n",
      "24. TechEndorse_7\n",
      "25. TechEndorse_8\n",
      "26. TechEndorse_9\n",
      "27. TechEndorse_13\n",
      "28. TechEndorse_13_TEXT\n",
      "29. TechOppose_1\n",
      "30. TechOppose_2\n",
      "31. TechOppose_3\n",
      "32. TechOppose_5\n",
      "33. TechOppose_7\n",
      "34. TechOppose_9\n",
      "35. TechOppose_11\n",
      "36. TechOppose_13\n",
      "37. TechOppose_16\n",
      "38. TechOppose_15\n",
      "39. TechOppose_15_TEXT\n",
      "40. Industry\n",
      "41. JobSatPoints_1\n",
      "42. JobSatPoints_2\n",
      "43. JobSatPoints_3\n",
      "44. JobSatPoints_4\n",
      "45. JobSatPoints_5\n",
      "46. JobSatPoints_6\n",
      "47. JobSatPoints_7\n",
      "48. JobSatPoints_8\n",
      "49. JobSatPoints_9\n",
      "50. JobSatPoints_10\n",
      "51. JobSatPoints_11\n",
      "52. JobSatPoints_13\n",
      "53. JobSatPoints_14\n",
      "54. JobSatPoints_15\n",
      "55. JobSatPoints_16\n",
      "56. AIThreat\n",
      "57. NewRole\n",
      "58. ToolCountWork\n",
      "59. ToolCountPersonal\n",
      "60. Country\n",
      "61. Currency\n",
      "62. CompTotal\n",
      "63. LanguageChoice\n",
      "64. LanguageHaveWorkedWith\n",
      "65. LanguageWantToWorkWith\n",
      "66. LanguageAdmired\n",
      "67. LanguagesHaveEntry\n",
      "68. LanguagesWantEntry\n",
      "69. DatabaseChoice\n",
      "70. DatabaseHaveWorkedWith\n",
      "71. DatabaseWantToWorkWith\n",
      "72. DatabaseAdmired\n",
      "73. DatabaseHaveEntry\n",
      "74. DatabaseWantEntry\n",
      "75. PlatformChoice\n",
      "76. PlatformHaveWorkedWith\n",
      "77. PlatformWantToWorkWith\n",
      "78. PlatformAdmired\n",
      "79. PlatformHaveEntry\n",
      "80. PlatformWantEntry\n",
      "81. WebframeChoice\n",
      "82. WebframeHaveWorkedWith\n",
      "83. WebframeWantToWorkWith\n",
      "84. WebframeAdmired\n",
      "85. WebframeHaveEntry\n",
      "86. WebframeWantEntry\n",
      "87. DevEnvsChoice\n",
      "88. DevEnvsHaveWorkedWith\n",
      "89. DevEnvsWantToWorkWith\n",
      "90. DevEnvsAdmired\n",
      "91. DevEnvHaveEntry\n",
      "92. DevEnvWantEntry\n",
      "93. SOTagsHaveWorkedWith\n",
      "94. SOTagsWantToWorkWith\n",
      "95. SOTagsAdmired\n",
      "96. OpSysPersonal use\n",
      "97. OpSysProfessional use\n",
      "98. OfficeStackAsyncHaveWorkedWith\n",
      "99. OfficeStackAsyncWantToWorkWith\n",
      "100. OfficeStackAsyncAdmired\n",
      "101. OfficeStackHaveEntry\n",
      "102. OfficeStackWantEntry\n",
      "103. CommPlatformHaveWorkedWith\n",
      "104. CommPlatformWantToWorkWith\n",
      "105. CommPlatformAdmired\n",
      "106. CommPlatformHaveEntr\n",
      "107. CommPlatformWantEntr\n",
      "108. AIModelsChoice\n",
      "109. AIModelsHaveWorkedWith\n",
      "110. AIModelsWantToWorkWith\n",
      "111. AIModelsAdmired\n",
      "112. SOAccount\n",
      "113. SOVisitFreq\n",
      "114. SODuration\n",
      "115. SOPartFreq\n",
      "116. SO_Dev_Content\n",
      "117. SO_Actions_1\n",
      "118. SO_Actions_16\n",
      "119. SO_Actions_3\n",
      "120. SO_Actions_4\n",
      "121. SO_Actions_5\n",
      "122. SO_Actions_6\n",
      "123. SO_Actions_9\n",
      "124. SO_Actions_7\n",
      "125. SO_Actions_10\n",
      "126. SO_Actions_15\n",
      "127. SOComm\n",
      "128. SOFriction\n",
      "129. AISelect\n",
      "130. AISent\n",
      "131. AIAcc\n",
      "132. AIComplex\n",
      "133. AIToolCurrently partially AI\n",
      "134. AIToolDon't plan to use AI for this task\n",
      "135. AIToolPlan to partially use AI\n",
      "136. AIToolPlan to mostly use AI\n",
      "137. AIToolCurrently mostly AI\n",
      "138. AIFrustration\n",
      "139. AIExplain\n",
      "140. AIAgents\n",
      "141. AIAgentChange\n",
      "142. AIAgent_Uses\n",
      "143. AgentUsesGeneral\n",
      "144. AIAgentImpactSomewhat agree\n",
      "145. AIAgentImpactNeutral\n",
      "146. AIAgentImpactSomewhat disagree\n",
      "147. AIAgentImpactStrongly agree\n",
      "148. AIAgentImpactStrongly disagree\n",
      "149. AIAgentChallengesNeutral\n",
      "150. AIAgentChallengesSomewhat disagree\n",
      "151. AIAgentChallengesStrongly agree\n",
      "152. AIAgentChallengesSomewhat agree\n",
      "153. AIAgentChallengesStrongly disagree\n",
      "154. AIAgentKnowledge\n",
      "155. AIAgentOrchestration\n",
      "156. AIAgentObserveSecure\n",
      "157. AIAgentExternal\n",
      "158. AIHuman\n",
      "159. AIOpen\n",
      "160. ConvertedCompYearly\n",
      "161. JobSat\n",
      "Average experience: 13.37 years\n",
      "Experience Median: 10.0 years\n",
      "The most popular experience (Mode): 0    10.0\n",
      "Name: WorkExp, dtype: float64 years\n"
     ]
    }
   ],
   "source": [
    "### Statistical Analysis of Years of Experience\n",
    "# Inspect the list of columns\n",
    "# Using enumerate to create a numbered list for easier reference\n",
    "for i, column in enumerate(sp_res.columns):\n",
    "    print(f\"{i}. {column}\")\n",
    "\n",
    "# 1. Calculate the Mean (Average)\n",
    "work_exp_mean = sp_res['WorkExp'].mean()\n",
    "\n",
    "# 2. Calculate the Median\n",
    "work_exp_median = sp_res['WorkExp'].median()\n",
    "\n",
    "# 3. Calculate the Mode\n",
    "# .mode() returns a Series, so we take the first values\n",
    "work_exp_mode = sp_res['WorkExp'].mode()\n",
    "\n",
    "print(f\"Average experience: {work_exp_mean:.2f} years\")\n",
    "print(f\"Experience Median: {work_exp_median} years\")\n",
    "print(f\"The most popular experience (Mode): {work_exp_mode} years\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c6b0c7-ce75-4b17-9a1d-a8251182fc7a",
   "metadata": {},
   "source": [
    "###### Insight 1: We have a bimodal distribution.\n",
    "###### We can observe two distinct major categories: junior professionals and experienced seniors.\n",
    "\n",
    "###### Insight 2: The mean being higher than the median indicates a right-skewed (positively skewed) distribution. \n",
    "###### The data is being pulled by high-experience specialists (outliers on the right)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1eb6956b-ada6-4322-b00b-5092e0d398ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Amount of only remote coworkers: 10931\n"
     ]
    }
   ],
   "source": [
    "#Remote work analysis\n",
    "remote_only_count = (sp_res['RemoteWork'] == 'Remote').sum()\n",
    "\n",
    "print(f\"\\Amount of only remote coworkers: {remote_only_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbcf1413-2fff-4214-a918-3c45540a592e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of Python-users: 58.3%\n"
     ]
    }
   ],
   "source": [
    "### Determining Python Popularity\n",
    "# 1. Determine the total number of respondents (non-null entries in the column)\n",
    "total_responses = sp_res['LanguageHaveWorkedWith'].count()\n",
    "\n",
    "# 2. Filter rows that contain 'Python'\n",
    "python_users = sp_res['LanguageHaveWorkedWith'].str.contains('Python', na=False).sum()\n",
    "\n",
    "# 3. Calculate the percentage of Python popularity among respondents\n",
    "python_percentage = (python_users / total_responses) * 100\n",
    "\n",
    "print(f\"The percentage of Python-users: {python_percentage:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96eca126-b138-4067-8ba5-177ac80a8764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning modalities: ['Online Courses or Certification (includes all media types);Other online resources (e.g. standard search, forum, online community)'\n",
      " 'Online Courses or Certification (includes all media types);Other online resources (e.g. standard search, forum, online community);Books / Physical media;Videos (not associated with specific online course or certification);Stack Overflow or Stack Exchange'\n",
      " 'Online Courses or Certification (includes all media types);Videos (not associated with specific online course or certification);Technical documentation (is generated for/by the tool or system)'\n",
      " 'Other online resources (e.g. standard search, forum, online community);Videos (not associated with specific online course or certification);Stack Overflow or Stack Exchange;Technical documentation (is generated for/by the tool or system);AI CodeGen tools or AI-enabled apps'\n",
      " nan]\n",
      "Amount of respondents who chose Online Courses or Certification: 10973 \n"
     ]
    }
   ],
   "source": [
    "### Analysis of Education Paths (Learning to Code)\n",
    "# 1. Inspect the unique values available in this column\n",
    "print(\"Learning modalities:\", sp_res['LearnCode'].unique()[:5]) \n",
    "\n",
    "# 2. Filter respondents who mentioned \"Online Courses\" as a learning method\n",
    "online_learners = sp_res['LearnCode'].str.contains('Online Courses or Certification ', na=False).sum()\n",
    "\n",
    "print(f\"Amount of respondents who chose Online Courses or Certification: {online_learners} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8d19e81-8ff8-41bc-abaa-61fc224e323f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Country  Average salary  \\\n",
      "112                                               Oman   390135.000000   \n",
      "3                                              Andorra   226103.500000   \n",
      "159                           United States of America   173298.590211   \n",
      "72                                              Israel   135828.365385   \n",
      "145                                        Switzerland   156456.600000   \n",
      "109                                            Nomadic   120131.571429   \n",
      "70                                             Ireland   120523.918919   \n",
      "87                                          Luxembourg   116014.714286   \n",
      "81                                          Kyrgyzstan   106008.500000   \n",
      "16                                              Belize   102121.000000   \n",
      "14                                             Belarus    93666.666667   \n",
      "65                                             Iceland    76083.000000   \n",
      "42                                             Denmark   115672.425000   \n",
      "8                                            Australia   118091.410423   \n",
      "157  United Kingdom of Great Britain and Northern I...   117662.362667   \n",
      "\n",
      "     Median salary  \n",
      "112       390135.0  \n",
      "3         226103.5  \n",
      "159       150000.0  \n",
      "72        142594.0  \n",
      "145       142592.0  \n",
      "109       139218.0  \n",
      "70        116015.0  \n",
      "87        109054.0  \n",
      "81        106008.5  \n",
      "16        102121.0  \n",
      "14        100000.0  \n",
      "65         99992.0  \n",
      "42         98289.0  \n",
      "8          97514.0  \n",
      "157        94958.5  \n"
     ]
    }
   ],
   "source": [
    "### Geographical Compensation Analysis for Python Developers\n",
    "# 1. Filter the dataset for respondents who know Python\n",
    "python_mask = sp_res['LanguageHaveWorkedWith'].str.contains('Python', na=False)\n",
    "\n",
    "# 2. Create a copy of the dataset for safe data manipulation (avoiding SettingWithCopyWarning)\n",
    "python_devs = sp_res[python_mask].copy()\n",
    "\n",
    "# 3. Group by country and calculate both the Mean and Median for the salary column\n",
    "# We use .agg() to calculate both metrics simultaneously\n",
    "salary_table = python_devs.groupby('Country')['ConvertedCompYearly'].agg(['mean', 'median']).reset_index()\n",
    "\n",
    "# 4. Rename columns for better readability\n",
    "salary_table.columns = ['Country', 'Average salary', 'Median salary']\n",
    "\n",
    "# 5. Sort by Median (as it is more representative) to identify top countries\n",
    "salary_table = salary_table.sort_values(by='Median salary', ascending=False)\n",
    "salary_table = salary_table.dropna()\n",
    "\n",
    "print(salary_table.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a9ca841-7a0e-434b-b6fa-40f857ffabdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education level of the Top 5-earning specialists:\n",
      "       ConvertedCompYearly                                          EdLevel\n",
      "34267           50000000.0              Associate degree (A.A., A.S., etc.)\n",
      "28700           33552715.0  Master’s degree (M.A., M.S., M.Eng., MBA, etc.)\n",
      "43143           18387548.0              Associate degree (A.A., A.S., etc.)\n",
      "35353           15430267.0     Bachelor’s degree (B.A., B.S., B.Eng., etc.)\n",
      "45971           13921760.0  Master’s degree (M.A., M.S., M.Eng., MBA, etc.)\n"
     ]
    }
   ],
   "source": [
    "### Analysis of Education Among Top-Earning Specialists\n",
    "# 1. Sort the entire dataset by salary in descending order\n",
    "# Using .sort_values to bring the highest salaries to the top\n",
    "top_paid = sp_res.sort_values(by='ConvertedCompYearly', ascending=False)\n",
    "\n",
    "# 2. Select the top 5 rows and specific columns for detailed analysis\n",
    "top_5_education = top_paid[['ConvertedCompYearly', 'EdLevel']].head(5)\n",
    "\n",
    "print(\"Education level of the Top 5-earning specialists:\")\n",
    "print(top_5_education)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86629ac4-eef4-4a26-9512-5afb56cb04fa",
   "metadata": {},
   "source": [
    "#### Key Insights:\n",
    "###### - A fascinating result: The highest-paid specialist in the database does not hold a formal university degree in CS. \n",
    "###### - This highlights \"Self-taught dominance\" in the industry, which is also observed in the 3rd position.\n",
    "###### - Two specialists hold an MBA! They have formal degrees in CS, professional engineering certifications, \n",
    "###### and most likely hold leadership or executive positions (Management)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6176aa49-e068-4820-a8cf-108736b80f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Age  Percentage\n",
      "0    18-24 years old       40.00\n",
      "3    45-54 years old       38.63\n",
      "4    55-64 years old       37.24\n",
      "1    25-34 years old       36.94\n",
      "2    35-44 years old       36.72\n",
      "5  65 years or older       31.63\n",
      "6  Prefer not to say       31.22\n"
     ]
    }
   ],
   "source": [
    "### Python Popularity Across Age Categories\n",
    "# To perform this analysis, we focus on the 'Age' and 'LanguageHaveWorkedWith' columns\n",
    "# 1. Feature Engineering: Create a boolean flag (True if the respondent knows Python, False otherwise)\n",
    "# Using .loc[:] to ensure we are working with the dataframe correctly\n",
    "sp_res=sp_res.copy()\n",
    "sp_res.loc[:, 'IsPythonUser'] = sp_res['LanguageHaveWorkedWith'].str.contains('Python', na=False)\n",
    "\n",
    "# 2. Group by Age and calculate the mean of the boolean column \n",
    "# (The mean of a boolean column effectively gives the proportion of 'True' values)\n",
    "age_stats = sp_res.groupby('Age')['IsPythonUser'].mean().reset_index()\n",
    "\n",
    "# 3. Convert proportions to percentages and sort the results\n",
    "age_stats['Percentage'] = (age_stats['IsPythonUser'] * 100).round(2)\n",
    "python_by_age = age_stats[['Age', 'Percentage']].sort_values(by='Percentage', ascending=False)\n",
    "\n",
    "print(python_by_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27564ba-04da-474a-9035-d16209192596",
   "metadata": {},
   "source": [
    "#### Key Insight:\n",
    "##### It appears Python is a language for all ages! \n",
    "##### The steady penetration of this technology across all age groups is highly encouraging and demonstrates its universal appeal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27f3edfe-d20c-4d36-b092-a38f1b9f2f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75th Percentile boundary: $120,596.00\n",
      "\n",
      "Top-industries:\n",
      "Industry\n",
      "Software Development                          1186\n",
      "Fintech                                        190\n",
      "Healthcare                                     188\n",
      "Other:                                         176\n",
      "Internet, Telecomm or Information Services     138\n",
      "Banking/Financial Services                      88\n",
      "Government                                      78\n",
      "Media & Advertising Services                    75\n",
      "Retail and Consumer Services                    65\n",
      "Transportation, or Supply Chain                 63\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Industry Analysis of High-Earning Remote Workers\n",
    "# 1. Identify the 75th percentile (0.75 quantile) for salary\n",
    "# This allows us to statistically define \"high-earning\" based on the data distribution\n",
    "q75 = sp_res['ConvertedCompYearly'].quantile(0.75)\n",
    "\n",
    "# 2. Filter for high-earning remote workers\n",
    "top_salary_remote = (sp_res['ConvertedCompYearly'] > q75) & (sp_res['RemoteWork'] == 'Remote')\n",
    "top_salary_remote_devs = sp_res.loc[top_salary_remote].copy()\n",
    "\n",
    "# 3. Identify the most popular industries within this specific group\n",
    "top_industries = top_salary_remote_devs['Industry'].value_counts().head(10)\n",
    "\n",
    "print(f\"75th Percentile boundary: ${q75:,.2f}\")\n",
    "print(\"\\nTop-industries:\")\n",
    "print(top_industries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e63a6f-6aba-44fc-9ed5-cd3c6f515b3f",
   "metadata": {},
   "source": [
    "#### Key Insights:\n",
    "##### - The results are expected for the high pay/remote work combination:\n",
    "#####   Software Development is the most flexible industry for remote opportunities and a classic leader in compensation.\n",
    "##### - Fintech: High salaries are driven by significant responsibility and strict personal data security requirements.\n",
    "##### - Healthcare: High demand due to personal data management and the need to collect, process, \n",
    "##### and store vast amounts of critical information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed3bbef-43ab-4842-8a8b-1f6a83310802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
